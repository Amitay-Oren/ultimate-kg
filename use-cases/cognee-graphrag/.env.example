# Cognee MCP Server Environment Configuration
# Copy this file to the cognee-mcp directory as .env

# =============================================================================
# REQUIRED: LLM API Configuration
# =============================================================================
# OpenAI API key for embeddings and LLM operations
LLM_API_KEY=your_openai_key_here

# Alternative: if you prefer to use OPENAI_API_KEY environment variable
# OPENAI_API_KEY=your_openai_key_here

# =============================================================================
# DATABASE PROVIDER SELECTION
# =============================================================================
# Vector Database: lancedb (embedded), qdrant, chromadb, weaviate
VECTOR_DB_PROVIDER=lancedb

# Graph Database: neo4j, networkx (default), kuzu
GRAPH_DATABASE_PROVIDER=neo4j

# Relational Database: sqlite (default), postgresql
DB_PROVIDER=sqlite

# =============================================================================
# NEO4J CONFIGURATION (if using neo4j as graph provider)
# =============================================================================
GRAPH_DATABASE_URL=bolt://localhost:7687
GRAPH_DATABASE_USERNAME=neo4j
GRAPH_DATABASE_PASSWORD=password123

# =============================================================================
# POSTGRESQL CONFIGURATION (if using postgresql as relational provider)
# =============================================================================
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=cognee
# DB_USER=cognee
# DB_PASSWORD=cognee_password

# =============================================================================
# QDRANT CONFIGURATION (if using qdrant as vector provider)
# =============================================================================
# QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your_qdrant_api_key

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# Embedding provider: openai, fastembed, sentence-transformers
EMBEDDING_PROVIDER=fastembed

# Embedding model (depends on provider)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSIONS=384
EMBEDDING_MAX_TOKENS=256

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# LLM provider: openai, anthropic, cohere
LLM_PROVIDER=openai

# LLM model name
LLM_MODEL=gpt-3.5-turbo

# Rate limiting
LLM_RATE_LIMIT_ENABLED=true
LLM_RATE_LIMIT_REQUESTS=100

# =============================================================================
# ENVIRONMENT SETTINGS
# =============================================================================
ENV=local

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# =============================================================================
# PROCESSING CONFIGURATION
# =============================================================================
# Document processing settings (optional)
# MAX_CONCURRENT_DOCUMENTS=5
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200